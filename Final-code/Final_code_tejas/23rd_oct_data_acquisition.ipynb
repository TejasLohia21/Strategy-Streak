{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task = Data Acquisition\n",
    "\n",
    "Author - Tejas Lohia\n",
    "\n",
    "Date - 23/10/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to acquire all the companies listed on Nasdaq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol                                  name exchange assetType  \\\n",
      "4    AACG                 ATA Creativity Global   NASDAQ     Stock   \n",
      "8    AADI                   Aadi Bioscience Inc   NASDAQ     Stock   \n",
      "9    AADR  ADVISORSHARES DORSEY WRIGHT ADR ETF    NASDAQ       ETF   \n",
      "10    AAL           American Airlines Group Inc   NASDAQ     Stock   \n",
      "14   AAME                Atlantic American Corp   NASDAQ     Stock   \n",
      "\n",
      "       ipoDate  delistingDate  status  \n",
      "4   2008-01-29            NaN  Active  \n",
      "8   2017-08-08            NaN  Active  \n",
      "9   2010-07-21            NaN  Active  \n",
      "10  2005-09-27            NaN  Active  \n",
      "14  1984-09-07            NaN  Active  \n",
      "(5227, 7)\n"
     ]
    }
   ],
   "source": [
    "api_key = \"LC2DGDLSUALZRVAN\"\n",
    "url = f\"https://www.alphavantage.co/query?function=LISTING_STATUS&apikey={api_key}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = pd.read_csv(io.StringIO(response.text))\n",
    "    nasdaq_stocks = data[data['exchange'] == 'NASDAQ']\n",
    "\n",
    "print(nasdaq_stocks.head())\n",
    "print(nasdaq_stocks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a csv file of all the nasdaq stocks companies only with symbol, name, exchange asnd asset type\n",
    "\n",
    "final_list = nasdaq_stocks[['symbol', 'name', 'exchange', 'assetType']]\n",
    "\n",
    "final_list.to_csv('nasdaq_stocks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now writing a code to acquire the historical data of the companies listed on Nasdaq.\n",
    "For each of the company, acquiring the historical data, and converting into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def historical_data(symbol):\n",
    "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = pd.read_csv(io.StringIO(response.text))\n",
    "        data = data.rename(columns={'timestamp': 'date'})\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        data.set_index('date', inplace=True)\n",
    "        data = data.sort_index()\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symbol_list = final_list['symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AACG', 'AADI', 'AADR', 'AAL', 'AAME', 'AAOI', 'AAON', 'AAPB', 'AAPD', 'AAPL']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open     High     Low   Close   Volume\n",
      "2008-01-29  9.5000   9.9900  8.5700  8.7500  1489000\n",
      "2008-01-30  8.7500   9.1500  8.3000  8.5000   219000\n",
      "2008-01-31  8.4900  10.3000  8.4900  9.5500   182300\n",
      "2008-02-01  9.9300   9.9400  9.5000  9.5100    28200\n",
      "2008-02-04  9.5000   9.7120  9.5000  9.5000     8300\n",
      "2008-02-05  9.2600   9.5000  9.0300  9.1100    29500\n",
      "2008-02-06  9.0000   9.4300  8.6700  9.0000    16000\n",
      "2008-02-07  9.0000   9.5000  9.0000  9.4000     6000\n",
      "2008-02-08  9.1200   9.2900  9.0000  9.0100     7900\n",
      "2008-02-11  9.0500   9.1700  9.0000  9.0400     3500\n",
      "(4210, 5)\n"
     ]
    }
   ],
   "source": [
    "def get_historical_data(symbol, function='TIME_SERIES_DAILY', output_size='full'):\n",
    "    url = f\"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": function,\n",
    "        \"symbol\": symbol,\n",
    "        \"apikey\": \"LC2DGDLSUALZRVAN\",\n",
    "        \"outputsize\": output_size,\n",
    "        \"datatype\": \"json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        time_series = data.get('Time Series (Daily)', {})  # Adjust according to function\n",
    "        if time_series:\n",
    "            df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "            df = df.rename(columns={\n",
    "                '1. open': 'Open',\n",
    "                '2. high': 'High',\n",
    "                '3. low': 'Low',\n",
    "                '4. close': 'Close',\n",
    "                '5. volume': 'Volume'\n",
    "            })\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            return df.sort_index()\n",
    "        else:\n",
    "            print(\"No data found.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "symbol = symbol_list[0]\n",
    "data = get_historical_data(symbol)\n",
    "if data is not None:\n",
    "    print(data[:10])  # Show the first few rows\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AACG...\n",
      "Saved AACG data to Hist_data/AACG.csv.\n",
      "Fetching data for AADI...\n",
      "Saved AADI data to Hist_data/AADI.csv.\n",
      "Fetching data for AADR...\n",
      "Saved AADR data to Hist_data/AADR.csv.\n",
      "Fetching data for AAL...\n",
      "Saved AAL data to Hist_data/AAL.csv.\n",
      "Fetching data for AAME...\n",
      "Saved AAME data to Hist_data/AAME.csv.\n",
      "Fetching data for AAOI...\n",
      "Saved AAOI data to Hist_data/AAOI.csv.\n",
      "Fetching data for AAON...\n",
      "Saved AAON data to Hist_data/AAON.csv.\n",
      "Fetching data for AAPB...\n",
      "Saved AAPB data to Hist_data/AAPB.csv.\n",
      "Fetching data for AAPD...\n",
      "Saved AAPD data to Hist_data/AAPD.csv.\n",
      "Fetching data for AAPL...\n",
      "Saved AAPL data to Hist_data/AAPL.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_historical_data(symbol, function='TIME_SERIES_DAILY', output_size='full'):\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": function,\n",
    "        \"symbol\": symbol,\n",
    "        \"apikey\": \"LC2DGDLSUALZRVAN\",  # Replace with your actual API key\n",
    "        \"outputsize\": output_size,\n",
    "        \"datatype\": \"json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        time_series = data.get('Time Series (Daily)', {})  # Adjust according to function\n",
    "        if time_series:\n",
    "            df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "            df = df.rename(columns={\n",
    "                '1. open': 'Open',\n",
    "                '2. high': 'High',\n",
    "                '3. low': 'Low',\n",
    "                '4. close': 'Close',\n",
    "                '5. volume': 'Volume'\n",
    "            })\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            return df.sort_index()\n",
    "        else:\n",
    "            print(f\"No data found for {symbol}.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error fetching data for {symbol}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def save_data_to_csv(symbol_list):\n",
    "    # Create a folder named 'Hist_data' if it doesn't exist\n",
    "    folder_name = 'Hist_data'\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    for symbol in symbol_list:\n",
    "        print(f\"Fetching data for {symbol}...\")\n",
    "        data = get_historical_data(symbol)\n",
    "        if data is not None:\n",
    "            file_path = os.path.join(folder_name, f\"{symbol}.csv\")\n",
    "            data.to_csv(file_path)\n",
    "            print(f\"Saved {symbol} data to {file_path}.\")\n",
    "        else:\n",
    "            print(f\"Skipping {symbol} due to missing data.\")\n",
    "\n",
    "# Example usage:\n",
    "  # Replace with your symbols\n",
    "save_data_to_csv(symbol_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zerodha_streak_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
