{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task = Data Acquisition\n",
    "\n",
    "Author - Tejas Lohia\n",
    "\n",
    "Date - 23/10/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to acquire all the companies listed on Nasdaq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol                                  name exchange assetType  \\\n",
      "4    AACG                 ATA Creativity Global   NASDAQ     Stock   \n",
      "8    AADI                   Aadi Bioscience Inc   NASDAQ     Stock   \n",
      "9    AADR  ADVISORSHARES DORSEY WRIGHT ADR ETF    NASDAQ       ETF   \n",
      "10    AAL           American Airlines Group Inc   NASDAQ     Stock   \n",
      "14   AAME                Atlantic American Corp   NASDAQ     Stock   \n",
      "\n",
      "       ipoDate  delistingDate  status  \n",
      "4   2008-01-29            NaN  Active  \n",
      "8   2017-08-08            NaN  Active  \n",
      "9   2010-07-21            NaN  Active  \n",
      "10  2005-09-27            NaN  Active  \n",
      "14  1984-09-07            NaN  Active  \n",
      "(5227, 7)\n"
     ]
    }
   ],
   "source": [
    "api_key = \"LC2DGDLSUALZRVAN\"\n",
    "url = f\"https://www.alphavantage.co/query?function=LISTING_STATUS&apikey={api_key}\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = pd.read_csv(io.StringIO(response.text))\n",
    "    nasdaq_stocks = data[data['exchange'] == 'NASDAQ']\n",
    "\n",
    "print(nasdaq_stocks.head())\n",
    "print(nasdaq_stocks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a csv file of all the nasdaq stocks companies only with symbol, name, exchange asnd asset type\n",
    "\n",
    "final_list = nasdaq_stocks[['symbol', 'name', 'exchange', 'assetType']]\n",
    "\n",
    "final_list.to_csv('nasdaq_stocks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now writing a code to acquire the historical data of the companies listed on Nasdaq.\n",
    "For each of the company, acquiring the historical data, and converting into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def historical_data(symbol):\n",
    "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = pd.read_csv(io.StringIO(response.text))\n",
    "        data = data.rename(columns={'timestamp': 'date'})\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "        data.set_index('date', inplace=True)\n",
    "        data = data.sort_index()\n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symbol_list = final_list['symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AACG', 'AADI', 'AADR', 'AAL', 'AAME', 'AAOI', 'AAON', 'AAPB', 'AAPD', 'AAPL']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AACG...\n",
      "Saved AACG data to Hist_data/AACG.csv.\n",
      "Fetching data for AADI...\n",
      "Saved AADI data to Hist_data/AADI.csv.\n",
      "Fetching data for AADR...\n",
      "Saved AADR data to Hist_data/AADR.csv.\n",
      "Fetching data for AAL...\n",
      "Saved AAL data to Hist_data/AAL.csv.\n",
      "Fetching data for AAME...\n",
      "Saved AAME data to Hist_data/AAME.csv.\n",
      "Fetching data for AAOI...\n",
      "Saved AAOI data to Hist_data/AAOI.csv.\n",
      "Fetching data for AAON...\n",
      "Saved AAON data to Hist_data/AAON.csv.\n",
      "Fetching data for AAPB...\n",
      "Saved AAPB data to Hist_data/AAPB.csv.\n",
      "Fetching data for AAPD...\n",
      "Saved AAPD data to Hist_data/AAPD.csv.\n",
      "Fetching data for AAPL...\n",
      "Saved AAPL data to Hist_data/AAPL.csv.\n"
     ]
    }
   ],
   "source": [
    "def get_historical_data(symbol, function='TIME_SERIES_DAILY', output_size='full'):\n",
    "    url = \"https://www.alphavantage.co/query\"\n",
    "    params = {\n",
    "        \"function\": function,\n",
    "        \"symbol\": symbol,\n",
    "        \"apikey\": \"LC2DGDLSUALZRVAN\", \n",
    "        \"outputsize\": output_size,\n",
    "        \"datatype\": \"json\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        time_series = data.get('Time Series (Daily)', {})\n",
    "        if time_series:\n",
    "            df = pd.DataFrame.from_dict(time_series, orient='index')\n",
    "            df = df.rename(columns={\n",
    "                '1. open': 'Open',\n",
    "                '2. high': 'High',\n",
    "                '3. low': 'Low',\n",
    "                '4. close': 'Close',\n",
    "                '5. volume': 'Volume'\n",
    "            })\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            return df.sort_index()\n",
    "        else:\n",
    "            print(f\"No data found for {symbol}.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error fetching data for {symbol}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def save_data_to_csv(symbol_list):\n",
    "    folder_name = 'Hist_data'\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    for symbol in symbol_list:\n",
    "        print(f\"Fetching data for {symbol}...\")\n",
    "        data = get_historical_data(symbol)\n",
    "        if data is not None:\n",
    "            file_path = os.path.join(folder_name, f\"{symbol}.csv\")\n",
    "            data.to_csv(file_path)\n",
    "            print(f\"Saved {symbol} data to {file_path}.\")\n",
    "        else:\n",
    "            print(f\"Skipping {symbol} due to missing data.\")\n",
    "\n",
    "save_data_to_csv(symbol_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zerodha_streak_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
